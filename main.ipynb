{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "news_df = pd.read_csv(\"data/Sora_LREC2020_biasedsentences.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seems that each instance consists of an article with sentences and a bias score between 1 and 4 is assigned to the article as a whole, the title, and each sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentence: [0]: LOUISVILLE - Dan Johnson posted a final message on Facebook to his friends and family on Wednesday afternoon. score: 3\n",
      "dataset score range: (np.int64(1), np.int64(4))\n"
     ]
    }
   ],
   "source": [
    "news_test_sentence = news_df.iloc[0] # visual inspection\n",
    "print(f\"sentence: {news_test_sentence['s0']}\", f\"score: {news_test_sentence['0']}\")\n",
    "print(f\"dataset score range: {news_df['article_bias'].min(),news_df['article_bias'].max()}\")\n",
    "# pd.DataFrame(news_test_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RobertaAdapterModel has generative capabilities, as `prepare_inputs_for_generation` is explicitly overwritten. However, it doesn't directly inherit from `GenerationMixin`. From ðŸ‘‰v4.50ðŸ‘ˆ onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.\n",
      "  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes\n",
      "  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).\n",
      "  - If you are not the owner of the model architecture class, please contact the model code owner to update it.\n",
      "Some weights of RobertaAdapterModel were not initialized from the model checkpoint at cardiffnlp/twitter-roberta-base-2022-154m and are newly initialized: ['heads.default.3.bias', 'roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8cd96ecf4c4c4a88b7ed6005727a5b7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 6 files:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\spiro\\LifeHub\\~Education\\~Leiden\\MSc\\Text mining\\Assignments\\venv\\Lib\\site-packages\\adapters\\loading.py:165: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(weights_file, map_location=\"cpu\")\n",
      "The model 'RobertaAdapterModel' is not supported for text-classification. Supported models are ['AlbertForSequenceClassification', 'BartForSequenceClassification', 'BertForSequenceClassification', 'BigBirdForSequenceClassification', 'BigBirdPegasusForSequenceClassification', 'BioGptForSequenceClassification', 'BloomForSequenceClassification', 'CamembertForSequenceClassification', 'CanineForSequenceClassification', 'LlamaForSequenceClassification', 'ConvBertForSequenceClassification', 'CTRLForSequenceClassification', 'Data2VecTextForSequenceClassification', 'DebertaForSequenceClassification', 'DebertaV2ForSequenceClassification', 'DistilBertForSequenceClassification', 'ElectraForSequenceClassification', 'ErnieForSequenceClassification', 'ErnieMForSequenceClassification', 'EsmForSequenceClassification', 'FalconForSequenceClassification', 'FlaubertForSequenceClassification', 'FNetForSequenceClassification', 'FunnelForSequenceClassification', 'GemmaForSequenceClassification', 'Gemma2ForSequenceClassification', 'GPT2ForSequenceClassification', 'GPT2ForSequenceClassification', 'GPTBigCodeForSequenceClassification', 'GPTNeoForSequenceClassification', 'GPTNeoXForSequenceClassification', 'GPTJForSequenceClassification', 'IBertForSequenceClassification', 'JambaForSequenceClassification', 'JetMoeForSequenceClassification', 'LayoutLMForSequenceClassification', 'LayoutLMv2ForSequenceClassification', 'LayoutLMv3ForSequenceClassification', 'LEDForSequenceClassification', 'LiltForSequenceClassification', 'LlamaForSequenceClassification', 'LongformerForSequenceClassification', 'LukeForSequenceClassification', 'MarkupLMForSequenceClassification', 'MBartForSequenceClassification', 'MegaForSequenceClassification', 'MegatronBertForSequenceClassification', 'MistralForSequenceClassification', 'MixtralForSequenceClassification', 'MobileBertForSequenceClassification', 'MPNetForSequenceClassification', 'MptForSequenceClassification', 'MraForSequenceClassification', 'MT5ForSequenceClassification', 'MvpForSequenceClassification', 'NemotronForSequenceClassification', 'NezhaForSequenceClassification', 'NystromformerForSequenceClassification', 'OpenLlamaForSequenceClassification', 'OpenAIGPTForSequenceClassification', 'OPTForSequenceClassification', 'PerceiverForSequenceClassification', 'PersimmonForSequenceClassification', 'PhiForSequenceClassification', 'Phi3ForSequenceClassification', 'PLBartForSequenceClassification', 'QDQBertForSequenceClassification', 'Qwen2ForSequenceClassification', 'Qwen2MoeForSequenceClassification', 'ReformerForSequenceClassification', 'RemBertForSequenceClassification', 'RobertaForSequenceClassification', 'RobertaPreLayerNormForSequenceClassification', 'RoCBertForSequenceClassification', 'RoFormerForSequenceClassification', 'SqueezeBertForSequenceClassification', 'StableLmForSequenceClassification', 'Starcoder2ForSequenceClassification', 'T5ForSequenceClassification', 'TapasForSequenceClassification', 'TransfoXLForSequenceClassification', 'UMT5ForSequenceClassification', 'XLMForSequenceClassification', 'XLMRobertaForSequenceClassification', 'XLMRobertaXLForSequenceClassification', 'XLNetForSequenceClassification', 'XmodForSequenceClassification', 'YosoForSequenceClassification'].\n"
     ]
    }
   ],
   "source": [
    "# model source: https://huggingface.co/cardiffnlp/twitter-roberta-base-2022-\n",
    "# adapter source: https://huggingface.co/SOUMYADEEPSAR/text_level_bias_roberta-twitter\n",
    "from transformers import AutoTokenizer, TFAutoModelForSequenceClassification\n",
    "from transformers import pipeline\n",
    "from adapters import AutoAdapterModel\n",
    "tokeniser = AutoTokenizer.from_pretrained(\"cardiffnlp/twitter-roberta-base-2022-154m\")\n",
    "model = AutoAdapterModel.from_pretrained(\"cardiffnlp/twitter-roberta-base-2022-154m\")\n",
    "adapter = model.load_adapter(\"SOUMYADEEPSAR/text_level_bias1\", set_active=True)\n",
    "classifier = pipeline('text-classification', model=model, tokenizer=tokeniser) # cuda = 0,1 based on gpu availability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preprocess news data\n",
    "def extract_sentences_and_labels(df):\n",
    "    sentences_list = []\n",
    "    labels_list = []\n",
    "    for _, row in df.iterrows():\n",
    "        for i in range(0, 20):  # Sentences are named f\"s0\" to f\"s19\"\n",
    "            if type(row[f\"s{i}\"]) == str: # skipping nan sentences\n",
    "                sentences_list.append(row[f\"s{i}\"])\n",
    "                labels_list.append(labels_to_binary(row[f\"{i}\"]))\n",
    "            \n",
    "    return sentences_list, labels_list\n",
    "\n",
    "sentences, labels = extract_sentences_and_labels(news_df)\n",
    "baseline_tokeniser = tokeniser\n",
    "inputs = baseline_tokeniser(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(inputs[\"input_ids\"], labels, test_size = 0.1, shuffle = True, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size = 0.1, shuffle = True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred: 0, y: 1\n"
     ]
    }
   ],
   "source": [
    "def labels_to_binary(label: int):\n",
    "    return 0 if label == 1 or label == 2 else 1\n",
    "\n",
    "# comparing bias score obtained from classifier to true bias score for a test sentence from the news dataset\n",
    "test_sent_pred = classifier(news_test_sentence[\"s0\"])\n",
    "test_sent_pred = test_sent_pred[-1]['label']\n",
    "test_sent_y = labels_to_binary(news_test_sentence[\"0\"])\n",
    "print(f\"pred: {test_sent_pred}, y: {test_sent_y}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:03,  3.20s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 19\u001b[0m\n\u001b[0;32m     17\u001b[0m             y\u001b[38;5;241m.\u001b[39mappend(labels_to_binary(row[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msent_idx\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m]))\n\u001b[0;32m     18\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m pred, y\n\u001b[1;32m---> 19\u001b[0m pred, y \u001b[38;5;241m=\u001b[39m \u001b[43meval_classifier\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnews_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclassifier\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[6], line 13\u001b[0m, in \u001b[0;36meval_classifier\u001b[1;34m(df, classifier)\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m sent_idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m20\u001b[39m):\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 13\u001b[0m         pred\u001b[38;5;241m.\u001b[39mappend(\u001b[43mclassifier\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43ms\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43msent_idx\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m     14\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m:\n\u001b[0;32m     15\u001b[0m         \u001b[38;5;66;03m# Todo: add if statement checking if nan\u001b[39;00m\n\u001b[0;32m     16\u001b[0m         pred\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;241m0\u001b[39m) \u001b[38;5;66;03m# seems (?) to be the case that for NaNs, minimum bias is assigned\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\spiro\\LifeHub\\~Education\\~Leiden\\MSc\\Text mining\\Assignments\\venv\\Lib\\site-packages\\transformers\\pipelines\\text_classification.py:156\u001b[0m, in \u001b[0;36mTextClassificationPipeline.__call__\u001b[1;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[0;32m    122\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;124;03mClassify the text(s) given as inputs.\u001b[39;00m\n\u001b[0;32m    124\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    153\u001b[0m \u001b[38;5;124;03m    If `top_k` is used, one such dictionary is returned per label.\u001b[39;00m\n\u001b[0;32m    154\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    155\u001b[0m inputs \u001b[38;5;241m=\u001b[39m (inputs,)\n\u001b[1;32m--> 156\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    157\u001b[0m \u001b[38;5;66;03m# TODO try and retrieve it in a nicer way from _sanitize_parameters.\u001b[39;00m\n\u001b[0;32m    158\u001b[0m _legacy \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtop_k\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m kwargs\n",
      "File \u001b[1;32mc:\\Users\\spiro\\LifeHub\\~Education\\~Leiden\\MSc\\Text mining\\Assignments\\venv\\Lib\\site-packages\\transformers\\pipelines\\base.py:1268\u001b[0m, in \u001b[0;36mPipeline.__call__\u001b[1;34m(self, inputs, num_workers, batch_size, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1260\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mnext\u001b[39m(\n\u001b[0;32m   1261\u001b[0m         \u001b[38;5;28miter\u001b[39m(\n\u001b[0;32m   1262\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_iterator(\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1265\u001b[0m         )\n\u001b[0;32m   1266\u001b[0m     )\n\u001b[0;32m   1267\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1268\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_single\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreprocess_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforward_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpostprocess_params\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\spiro\\LifeHub\\~Education\\~Leiden\\MSc\\Text mining\\Assignments\\venv\\Lib\\site-packages\\transformers\\pipelines\\base.py:1275\u001b[0m, in \u001b[0;36mPipeline.run_single\u001b[1;34m(self, inputs, preprocess_params, forward_params, postprocess_params)\u001b[0m\n\u001b[0;32m   1273\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun_single\u001b[39m(\u001b[38;5;28mself\u001b[39m, inputs, preprocess_params, forward_params, postprocess_params):\n\u001b[0;32m   1274\u001b[0m     model_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpreprocess(inputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpreprocess_params)\n\u001b[1;32m-> 1275\u001b[0m     model_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mforward_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1276\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpostprocess(model_outputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpostprocess_params)\n\u001b[0;32m   1277\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n",
      "File \u001b[1;32mc:\\Users\\spiro\\LifeHub\\~Education\\~Leiden\\MSc\\Text mining\\Assignments\\venv\\Lib\\site-packages\\transformers\\pipelines\\base.py:1175\u001b[0m, in \u001b[0;36mPipeline.forward\u001b[1;34m(self, model_inputs, **forward_params)\u001b[0m\n\u001b[0;32m   1173\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m inference_context():\n\u001b[0;32m   1174\u001b[0m         model_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ensure_tensor_on_device(model_inputs, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m-> 1175\u001b[0m         model_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mforward_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1176\u001b[0m         model_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ensure_tensor_on_device(model_outputs, device\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[0;32m   1177\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\spiro\\LifeHub\\~Education\\~Leiden\\MSc\\Text mining\\Assignments\\venv\\Lib\\site-packages\\transformers\\pipelines\\text_classification.py:187\u001b[0m, in \u001b[0;36mTextClassificationPipeline._forward\u001b[1;34m(self, model_inputs)\u001b[0m\n\u001b[0;32m    185\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muse_cache\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39msignature(model_forward)\u001b[38;5;241m.\u001b[39mparameters\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[0;32m    186\u001b[0m     model_inputs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muse_cache\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m--> 187\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\spiro\\LifeHub\\~Education\\~Leiden\\MSc\\Text mining\\Assignments\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\spiro\\LifeHub\\~Education\\~Leiden\\MSc\\Text mining\\Assignments\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\spiro\\LifeHub\\~Education\\~Leiden\\MSc\\Text mining\\Assignments\\venv\\Lib\\site-packages\\adapters\\models\\roberta\\adapter_model.py:70\u001b[0m, in \u001b[0;36mRobertaAdapterModel.forward\u001b[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, output_attentions, output_hidden_states, return_dict, head, output_adapter_gating_scores, output_adapter_fusion_attentions, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m inputs_embeds \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     63\u001b[0m     inputs_embeds\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, inputs_embeds\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m), inputs_embeds\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m     64\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m inputs_embeds \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     65\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     66\u001b[0m )\n\u001b[0;32m     68\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[1;32m---> 70\u001b[0m outputs, context \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mroberta\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     71\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     72\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     73\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     74\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     75\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     76\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     77\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     78\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     79\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     80\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_adapter_gating_scores\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_adapter_gating_scores\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     81\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_adapter_fusion_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_adapter_fusion_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     82\u001b[0m \u001b[43m    \u001b[49m\u001b[43madapter_input_parallelized\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43madapter_input_parallelized\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     83\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_context\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     84\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     85\u001b[0m \u001b[38;5;66;03m# required e.g. for prompt tuning in all models\u001b[39;00m\n\u001b[0;32m     86\u001b[0m kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontext\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m context\n",
      "File \u001b[1;32mc:\\Users\\spiro\\LifeHub\\~Education\\~Leiden\\MSc\\Text mining\\Assignments\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\spiro\\LifeHub\\~Education\\~Leiden\\MSc\\Text mining\\Assignments\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\spiro\\LifeHub\\~Education\\~Leiden\\MSc\\Text mining\\Assignments\\venv\\Lib\\site-packages\\adapters\\context.py:116\u001b[0m, in \u001b[0;36mForwardContext.wrap.<locals>.wrapper_func\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    112\u001b[0m output_context \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput_context\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m    113\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    114\u001b[0m     k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m k\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput_\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mcontext_attributes\n\u001b[0;32m    115\u001b[0m }\n\u001b[1;32m--> 116\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    118\u001b[0m \u001b[38;5;66;03m# append output attributes\u001b[39;00m\n\u001b[0;32m    119\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(results, \u001b[38;5;28mtuple\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\spiro\\LifeHub\\~Education\\~Leiden\\MSc\\Text mining\\Assignments\\venv\\Lib\\site-packages\\adapters\\model_mixin.py:1470\u001b[0m, in \u001b[0;36mModelBaseAdaptersMixin.forward\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1468\u001b[0m \u001b[38;5;129m@ForwardContext\u001b[39m\u001b[38;5;241m.\u001b[39mwrap\n\u001b[0;32m   1469\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m-> 1470\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\spiro\\LifeHub\\~Education\\~Leiden\\MSc\\Text mining\\Assignments\\venv\\Lib\\site-packages\\transformers\\models\\roberta\\modeling_roberta.py:976\u001b[0m, in \u001b[0;36mRobertaModel.forward\u001b[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    969\u001b[0m \u001b[38;5;66;03m# Prepare head mask if needed\u001b[39;00m\n\u001b[0;32m    970\u001b[0m \u001b[38;5;66;03m# 1.0 in head_mask indicate we keep the head\u001b[39;00m\n\u001b[0;32m    971\u001b[0m \u001b[38;5;66;03m# attention_probs has shape bsz x n_heads x N x N\u001b[39;00m\n\u001b[0;32m    972\u001b[0m \u001b[38;5;66;03m# input head_mask has shape [num_heads] or [num_hidden_layers x num_heads]\u001b[39;00m\n\u001b[0;32m    973\u001b[0m \u001b[38;5;66;03m# and head_mask is converted to shape [num_hidden_layers x batch x num_heads x seq_length x seq_length]\u001b[39;00m\n\u001b[0;32m    974\u001b[0m head_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_head_mask(head_mask, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mnum_hidden_layers)\n\u001b[1;32m--> 976\u001b[0m encoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    977\u001b[0m \u001b[43m    \u001b[49m\u001b[43membedding_output\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    978\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    979\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    980\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    981\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_extended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    982\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    983\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    984\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    985\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    986\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    987\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    988\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m encoder_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    989\u001b[0m pooled_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler(sequence_output) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\spiro\\LifeHub\\~Education\\~Leiden\\MSc\\Text mining\\Assignments\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\spiro\\LifeHub\\~Education\\~Leiden\\MSc\\Text mining\\Assignments\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\spiro\\LifeHub\\~Education\\~Leiden\\MSc\\Text mining\\Assignments\\venv\\Lib\\site-packages\\transformers\\models\\roberta\\modeling_roberta.py:631\u001b[0m, in \u001b[0;36mRobertaEncoder.forward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    620\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[0;32m    621\u001b[0m         layer_module\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[0;32m    622\u001b[0m         hidden_states,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    628\u001b[0m         output_attentions,\n\u001b[0;32m    629\u001b[0m     )\n\u001b[0;32m    630\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 631\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mlayer_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    632\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    633\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    634\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    635\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    636\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    637\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    638\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    639\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    641\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    642\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n",
      "File \u001b[1;32mc:\\Users\\spiro\\LifeHub\\~Education\\~Leiden\\MSc\\Text mining\\Assignments\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\spiro\\LifeHub\\~Education\\~Leiden\\MSc\\Text mining\\Assignments\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1844\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1841\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m inner()\n\u001b[0;32m   1843\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1844\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1845\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m   1846\u001b[0m     \u001b[38;5;66;03m# run always called hooks if they have not already been run\u001b[39;00m\n\u001b[0;32m   1847\u001b[0m     \u001b[38;5;66;03m# For now only forward hooks have the always_call option but perhaps\u001b[39;00m\n\u001b[0;32m   1848\u001b[0m     \u001b[38;5;66;03m# this functionality should be added to full backward hooks as well.\u001b[39;00m\n\u001b[0;32m   1849\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m hook_id, hook \u001b[38;5;129;01min\u001b[39;00m _global_forward_hooks\u001b[38;5;241m.\u001b[39mitems():\n",
      "File \u001b[1;32mc:\\Users\\spiro\\LifeHub\\~Education\\~Leiden\\MSc\\Text mining\\Assignments\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1790\u001b[0m, in \u001b[0;36mModule._call_impl.<locals>.inner\u001b[1;34m()\u001b[0m\n\u001b[0;32m   1787\u001b[0m     bw_hook \u001b[38;5;241m=\u001b[39m BackwardHook(\u001b[38;5;28mself\u001b[39m, full_backward_hooks, backward_pre_hooks)\n\u001b[0;32m   1788\u001b[0m     args \u001b[38;5;241m=\u001b[39m bw_hook\u001b[38;5;241m.\u001b[39msetup_input_hook(args)\n\u001b[1;32m-> 1790\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1791\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks:\n\u001b[0;32m   1792\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m hook_id, hook \u001b[38;5;129;01min\u001b[39;00m (\n\u001b[0;32m   1793\u001b[0m         \u001b[38;5;241m*\u001b[39m_global_forward_hooks\u001b[38;5;241m.\u001b[39mitems(),\n\u001b[0;32m   1794\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks\u001b[38;5;241m.\u001b[39mitems(),\n\u001b[0;32m   1795\u001b[0m     ):\n\u001b[0;32m   1796\u001b[0m         \u001b[38;5;66;03m# mark that always called hook is run\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\spiro\\LifeHub\\~Education\\~Leiden\\MSc\\Text mining\\Assignments\\venv\\Lib\\site-packages\\transformers\\models\\roberta\\modeling_roberta.py:562\u001b[0m, in \u001b[0;36mRobertaLayer.forward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[0;32m    559\u001b[0m     cross_attn_present_key_value \u001b[38;5;241m=\u001b[39m cross_attention_outputs[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m    560\u001b[0m     present_key_value \u001b[38;5;241m=\u001b[39m present_key_value \u001b[38;5;241m+\u001b[39m cross_attn_present_key_value\n\u001b[1;32m--> 562\u001b[0m layer_output \u001b[38;5;241m=\u001b[39m \u001b[43mapply_chunking_to_forward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    563\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeed_forward_chunk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchunk_size_feed_forward\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mseq_len_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_output\u001b[49m\n\u001b[0;32m    564\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    565\u001b[0m outputs \u001b[38;5;241m=\u001b[39m (layer_output,) \u001b[38;5;241m+\u001b[39m outputs\n\u001b[0;32m    567\u001b[0m \u001b[38;5;66;03m# if decoder, return the attn key/values as the last output\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\spiro\\LifeHub\\~Education\\~Leiden\\MSc\\Text mining\\Assignments\\venv\\Lib\\site-packages\\transformers\\pytorch_utils.py:248\u001b[0m, in \u001b[0;36mapply_chunking_to_forward\u001b[1;34m(forward_fn, chunk_size, chunk_dim, *input_tensors)\u001b[0m\n\u001b[0;32m    245\u001b[0m     \u001b[38;5;66;03m# concatenate output at same dimension\u001b[39;00m\n\u001b[0;32m    246\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcat(output_chunks, dim\u001b[38;5;241m=\u001b[39mchunk_dim)\n\u001b[1;32m--> 248\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minput_tensors\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\spiro\\LifeHub\\~Education\\~Leiden\\MSc\\Text mining\\Assignments\\venv\\Lib\\site-packages\\transformers\\models\\roberta\\modeling_roberta.py:574\u001b[0m, in \u001b[0;36mRobertaLayer.feed_forward_chunk\u001b[1;34m(self, attention_output)\u001b[0m\n\u001b[0;32m    573\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfeed_forward_chunk\u001b[39m(\u001b[38;5;28mself\u001b[39m, attention_output):\n\u001b[1;32m--> 574\u001b[0m     intermediate_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mintermediate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mattention_output\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    575\u001b[0m     layer_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput(intermediate_output, attention_output)\n\u001b[0;32m    576\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m layer_output\n",
      "File \u001b[1;32mc:\\Users\\spiro\\LifeHub\\~Education\\~Leiden\\MSc\\Text mining\\Assignments\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\spiro\\LifeHub\\~Education\\~Leiden\\MSc\\Text mining\\Assignments\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\spiro\\LifeHub\\~Education\\~Leiden\\MSc\\Text mining\\Assignments\\venv\\Lib\\site-packages\\transformers\\models\\roberta\\modeling_roberta.py:472\u001b[0m, in \u001b[0;36mRobertaIntermediate.forward\u001b[1;34m(self, hidden_states)\u001b[0m\n\u001b[0;32m    471\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, hidden_states: torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[1;32m--> 472\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdense\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    473\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mintermediate_act_fn(hidden_states)\n\u001b[0;32m    474\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m hidden_states\n",
      "File \u001b[1;32mc:\\Users\\spiro\\LifeHub\\~Education\\~Leiden\\MSc\\Text mining\\Assignments\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\spiro\\LifeHub\\~Education\\~Leiden\\MSc\\Text mining\\Assignments\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\spiro\\LifeHub\\~Education\\~Leiden\\MSc\\Text mining\\Assignments\\venv\\Lib\\site-packages\\adapters\\methods\\lora.py:515\u001b[0m, in \u001b[0;36mLoRALinear.forward\u001b[1;34m(self, input_states)\u001b[0m\n\u001b[0;32m    513\u001b[0m     layer_output \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mlinear(input_states, weight, bias\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias)\n\u001b[0;32m    514\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 515\u001b[0m     layer_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmerged:\n\u001b[0;32m    518\u001b[0m     adapter_setup \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_active_setup()\n",
      "File \u001b[1;32mc:\\Users\\spiro\\LifeHub\\~Education\\~Leiden\\MSc\\Text mining\\Assignments\\venv\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:125\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 125\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "test = False\n",
    "def eval_classifier(df, classifier):\n",
    "    pred = []\n",
    "    y = []\n",
    "    count = 0\n",
    "    for row_idx,row in tqdm(df.iterrows()):\n",
    "        if test and row_idx < 20:\n",
    "            continue\n",
    "        if test and row_idx == 30:\n",
    "            break\n",
    "        for sent_idx in range(20):\n",
    "            try:\n",
    "                pred.append(classifier(row[f\"s{sent_idx}\"])[-1][\"label\"])\n",
    "            except ValueError:\n",
    "                # Todo: add if statement checking if nan\n",
    "                pred.append(0) # seems (?) to be the case that for NaNs, minimum bias is assigned\n",
    "            y.append(labels_to_binary(row[f\"{sent_idx}\"]))\n",
    "    return pred, y\n",
    "pred, y = eval_classifier(news_df, classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = False\n",
    "def eval_classifier(df, classifier):\n",
    "    pred = []\n",
    "    y = []\n",
    "    count = 0\n",
    "    for row_idx,row in tqdm(df.iterrows()):\n",
    "        if test and row_idx < 20:\n",
    "            continue\n",
    "        if test and row_idx == 30:\n",
    "            break\n",
    "        for sent_idx in range(20):\n",
    "            try:\n",
    "                pred.append(classifier(row[f\"s{sent_idx}\"])[-1][\"label\"])\n",
    "            except ValueError:\n",
    "                # Todo: add if statement checking if nan\n",
    "                pred.append(0) # seems (?) to be the case that for NaNs, minimum bias is assigned\n",
    "            y.append(labels_to_binary(row[f\"{sent_idx}\"]))\n",
    "    return pred, y\n",
    "pred, y = eval_classifier(news_df, classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_accuracy(pred, y):\n",
    "    pred_copy = [np.int64(label) for label in pred]\n",
    "    y_copy = [np.int64(label) for label in y]\n",
    "    count = 0\n",
    "    for index,label in enumerate(pred_copy):\n",
    "        if y_copy[index] == label:\n",
    "            count += 1\n",
    "    return count/len(pred_copy)\n",
    "# calc_accuracy(pred, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine tune classifier and compare to baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "train_dataset = Dataset.from_dict({\n",
    "    'input_ids': X_train,\n",
    "    'label': y_train\n",
    "})\n",
    "\n",
    "eval_dataset = Dataset.from_dict({\n",
    "    'input_ids':X_val,\n",
    "    'label': y_val\n",
    "})\n",
    "\n",
    "test_dataset = Dataset.from_dict({\n",
    "    'input_ids':X_test,\n",
    "    'label':y_test\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(pred, y):\n",
    "    return calc_accuracy(pred,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments\n",
    "from transformers import Trainer\n",
    "test = True\n",
    "args = TrainingArguments(\n",
    "    \"baseline-bias-classifier\",\n",
    "    evaluation_strategy = \"epoch\",\n",
    "    save_strategy = \"epoch\",\n",
    "    learning_rate = 2e-5,\n",
    "    num_train_epochs = 3,\n",
    "    weight_decay = 0.01,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model = model,\n",
    "    args = args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset= eval_dataset,\n",
    "    tokenizer= baseline_tokeniser\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22c9071a1c194143a9c79f63733095e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1194 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ef527e6550c456c8cd0928e53de6c9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/45 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_runtime': 26.7795, 'eval_samples_per_second': 13.219, 'eval_steps_per_second': 1.68, 'epoch': 1.0}\n",
      "{'loss': 0.6684, 'grad_norm': 5.961797714233398, 'learning_rate': 1.1624790619765495e-05, 'epoch': 1.26}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17bda243261643adae42d438c74f11ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/45 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_runtime': 27.7307, 'eval_samples_per_second': 12.766, 'eval_steps_per_second': 1.623, 'epoch': 2.0}\n",
      "{'loss': 0.6364, 'grad_norm': 5.191866874694824, 'learning_rate': 3.2495812395309884e-06, 'epoch': 2.51}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1de07fdfd444b068bd1afe81bc00927",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/45 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_runtime': 31.2682, 'eval_samples_per_second': 11.321, 'eval_steps_per_second': 1.439, 'epoch': 3.0}\n",
      "{'train_runtime': 2928.2089, 'train_samples_per_second': 3.256, 'train_steps_per_second': 0.408, 'train_loss': 0.6480254168486476, 'epoch': 3.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1194, training_loss=0.6480254168486476, metrics={'train_runtime': 2928.2089, 'train_samples_per_second': 3.256, 'train_steps_per_second': 0.408, 'total_flos': 276629152145364.0, 'train_loss': 0.6480254168486476, 'epoch': 3.0})"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this seems like it will take very long (3hrs or so). Maybe we should get this to work with GPUs. I think that would involve using a data collator so that everything is the same shape.\n",
    "\n",
    "# fine-tuning\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "794079b9f6244aa88dd1a476501f40f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# obtaining predictions from fine-tuned model as logits\n",
    "predictions = trainer.predict(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PredictionOutput(predictions=(array([0.7038864 , 0.6937561 , 0.6639484 , 0.7868625 , 0.48734406,\n",
       "       0.9180164 , 0.46692032, 0.61046344, 0.73482084, 0.92367446,\n",
       "       0.67665315, 0.40204564, 0.5182122 , 0.61428994, 0.90572333,\n",
       "       0.5524112 , 0.5988605 , 0.6766929 , 0.5960391 , 0.80469024,\n",
       "       0.7320262 , 0.7888113 , 0.8483089 , 0.75849587, 0.73935497,\n",
       "       0.6702986 , 0.7388642 , 0.72211707, 0.7461526 , 0.5389875 ,\n",
       "       0.96301246, 0.418186  , 0.99670947, 0.86583173, 0.3600293 ,\n",
       "       0.85527205, 0.63864124, 0.81468713, 0.8616187 , 0.83753294,\n",
       "       0.6972611 , 0.5107569 , 0.7223513 , 0.55591244, 0.84153444,\n",
       "       0.97584426, 0.6572989 , 0.70701265, 0.6325366 , 1.5262616 ],\n",
       "      dtype=float32), array([[ 0.5572506 , -0.5410291 ],\n",
       "       [-0.36843497,  0.3525593 ],\n",
       "       [ 0.86653364, -0.8231727 ],\n",
       "       [ 0.47954106, -0.45747066],\n",
       "       [-0.42672837,  0.4048805 ],\n",
       "       [ 0.29323417, -0.2729563 ],\n",
       "       [ 0.39285076, -0.38551953],\n",
       "       [-0.22053103,  0.2031196 ],\n",
       "       [ 0.1176106 , -0.12814897],\n",
       "       [ 0.20743404, -0.21031326],\n",
       "       [-0.11430918,  0.0936719 ],\n",
       "       [ 0.40081936, -0.37754893],\n",
       "       [-0.26619238,  0.23510787],\n",
       "       [ 0.72294   , -0.68520194],\n",
       "       [ 0.19605117, -0.18608595],\n",
       "       [ 0.23587205, -0.21989194],\n",
       "       [ 0.66024697, -0.6324833 ],\n",
       "       [ 0.13552846, -0.13457137],\n",
       "       [ 0.5148132 , -0.4857221 ],\n",
       "       [ 0.8454711 , -0.7768974 ],\n",
       "       [ 0.14279704, -0.15892854],\n",
       "       [ 0.24743839, -0.24323188],\n",
       "       [ 0.26207253, -0.25973824],\n",
       "       [ 0.7048838 , -0.65595335],\n",
       "       [ 0.643545  , -0.6053912 ],\n",
       "       [ 0.7152584 , -0.656437  ],\n",
       "       [ 0.37956578, -0.34977648],\n",
       "       [ 0.7528909 , -0.7144418 ],\n",
       "       [ 0.50604004, -0.4794749 ],\n",
       "       [ 0.7417246 , -0.6681228 ],\n",
       "       [-0.36067018,  0.33262795],\n",
       "       [ 0.51148504, -0.48513567],\n",
       "       [ 0.1740517 , -0.17079276],\n",
       "       [ 0.3920946 , -0.38822514],\n",
       "       [ 0.66932434, -0.6375268 ],\n",
       "       [ 0.11527537, -0.11073567],\n",
       "       [ 0.85903674, -0.8122051 ],\n",
       "       [ 0.33309525, -0.31102806],\n",
       "       [ 0.07987224, -0.07978083],\n",
       "       [-0.41365686,  0.36356735],\n",
       "       [ 0.6338608 , -0.61111385],\n",
       "       [-0.4720667 ,  0.4411667 ],\n",
       "       [ 0.66350776, -0.6345712 ],\n",
       "       [ 0.06009744, -0.06345565],\n",
       "       [-0.4720667 ,  0.4411667 ],\n",
       "       [ 0.75450885, -0.69253623],\n",
       "       [ 0.7136079 , -0.6753226 ],\n",
       "       [ 0.6051633 , -0.5767741 ],\n",
       "       [ 0.47585854, -0.45087045],\n",
       "       [ 0.5584733 , -0.52853554],\n",
       "       [ 0.3272596 , -0.30829272],\n",
       "       [-0.5963001 ,  0.5761292 ],\n",
       "       [ 0.7846833 , -0.7264249 ],\n",
       "       [-0.10768386,  0.10326473],\n",
       "       [ 0.5902258 , -0.5555572 ],\n",
       "       [ 0.7751731 , -0.7216187 ],\n",
       "       [ 0.3623651 , -0.35237694],\n",
       "       [ 0.69227046, -0.65748876],\n",
       "       [ 0.1664965 , -0.17047085],\n",
       "       [ 0.4178288 , -0.3931402 ],\n",
       "       [ 0.6077663 , -0.5776809 ],\n",
       "       [ 0.47170097, -0.44702947],\n",
       "       [ 0.18340878, -0.18024941],\n",
       "       [ 0.57176167, -0.5545683 ],\n",
       "       [ 0.7555067 , -0.70437646],\n",
       "       [ 0.09248733, -0.09169993],\n",
       "       [-0.16376452,  0.13863799],\n",
       "       [-0.42672837,  0.4048805 ],\n",
       "       [-0.01179823,  0.01372962],\n",
       "       [ 0.5950316 , -0.5635217 ],\n",
       "       [-0.711748  ,  0.655992  ],\n",
       "       [ 0.6344518 , -0.5892696 ],\n",
       "       [-0.01179823,  0.01372962],\n",
       "       [ 0.67628294, -0.63148326],\n",
       "       [-0.02211238,  0.02174444],\n",
       "       [ 0.14952773, -0.13656512],\n",
       "       [ 0.26911244, -0.25137648],\n",
       "       [ 0.62517196, -0.59546864],\n",
       "       [ 0.41705263, -0.39718834],\n",
       "       [-0.26619232,  0.2351078 ],\n",
       "       [ 0.385912  , -0.36973885],\n",
       "       [-0.7324074 ,  0.7061649 ],\n",
       "       [ 0.05676445, -0.06326167],\n",
       "       [ 0.7514641 , -0.7310276 ],\n",
       "       [ 0.45855203, -0.42445537],\n",
       "       [ 0.40397823, -0.3953036 ],\n",
       "       [ 0.7029064 , -0.6605914 ],\n",
       "       [ 0.7015456 , -0.6584366 ],\n",
       "       [ 0.41880703, -0.39788702],\n",
       "       [ 0.5337377 , -0.5066873 ],\n",
       "       [-0.479702  ,  0.44467264],\n",
       "       [-0.4852407 ,  0.47047582],\n",
       "       [ 0.6731399 , -0.6333657 ],\n",
       "       [ 0.7947144 , -0.7458028 ],\n",
       "       [-0.55367213,  0.51836044],\n",
       "       [ 0.39467126, -0.38944823],\n",
       "       [-0.5478737 ,  0.50635195],\n",
       "       [ 0.05877275, -0.06513792],\n",
       "       [ 0.3067428 , -0.28800094],\n",
       "       [-0.01528387,  0.01070029],\n",
       "       [ 0.65187454, -0.60747415],\n",
       "       [ 0.5933033 , -0.5571422 ],\n",
       "       [ 0.7574535 , -0.7051004 ],\n",
       "       [ 0.08192147, -0.07836195],\n",
       "       [ 0.43558088, -0.42885077],\n",
       "       [ 0.40509436, -0.3928165 ],\n",
       "       [ 0.71309525, -0.67449206],\n",
       "       [ 0.36343586, -0.34693116],\n",
       "       [ 0.32044676, -0.29616886],\n",
       "       [ 0.35845077, -0.35111505],\n",
       "       [ 0.52358913, -0.50369227],\n",
       "       [-0.32045048,  0.3108533 ],\n",
       "       [ 0.6143623 , -0.5791643 ],\n",
       "       [ 0.44993842, -0.41219985],\n",
       "       [-0.9124192 ,  0.8744132 ],\n",
       "       [ 0.66075   , -0.6295957 ],\n",
       "       [ 0.17119344, -0.16615248],\n",
       "       [ 0.7065069 , -0.66258144],\n",
       "       [ 0.66333276, -0.6178631 ],\n",
       "       [ 0.3658113 , -0.3564201 ],\n",
       "       [ 0.07974453, -0.08093201],\n",
       "       [ 0.03404476, -0.03339441],\n",
       "       [ 0.8420227 , -0.79038435],\n",
       "       [ 0.8171392 , -0.77788466],\n",
       "       [ 0.5572506 , -0.5410291 ],\n",
       "       [-0.08927293,  0.08446122],\n",
       "       [ 0.46511215, -0.42698306],\n",
       "       [-0.55820256,  0.51191527],\n",
       "       [ 0.0715462 , -0.08236342],\n",
       "       [-0.14833054,  0.12506658],\n",
       "       [ 0.9310132 , -0.854222  ],\n",
       "       [ 0.6156529 , -0.5878152 ],\n",
       "       [ 0.6562819 , -0.6114184 ],\n",
       "       [ 0.51199   , -0.4781105 ],\n",
       "       [ 0.2235847 , -0.23346376],\n",
       "       [ 0.48932943, -0.4875946 ],\n",
       "       [-0.5899834 ,  0.5593144 ],\n",
       "       [ 0.10879503, -0.1155718 ],\n",
       "       [-0.68702227,  0.645225  ],\n",
       "       [-0.02924394,  0.02213927],\n",
       "       [ 0.73036647, -0.69208616],\n",
       "       [ 0.39560375, -0.3881056 ],\n",
       "       [ 0.44496417, -0.4239595 ],\n",
       "       [ 0.7065534 , -0.67000306],\n",
       "       [ 0.08192165, -0.07836212],\n",
       "       [ 0.16541643, -0.15287901],\n",
       "       [ 0.27969667, -0.2829131 ],\n",
       "       [ 0.09498382, -0.09580116],\n",
       "       [ 0.55847317, -0.52853554],\n",
       "       [ 0.38415605, -0.36604866],\n",
       "       [ 0.2860519 , -0.26306707],\n",
       "       [-0.35326877,  0.3431326 ],\n",
       "       [ 0.6731401 , -0.6333659 ],\n",
       "       [ 0.8227764 , -0.7775369 ],\n",
       "       [ 0.16541633, -0.1528789 ],\n",
       "       [-0.5356174 ,  0.5105414 ],\n",
       "       [-0.46167186,  0.43642804],\n",
       "       [-0.6188739 ,  0.59819496],\n",
       "       [-0.50226223,  0.49365267],\n",
       "       [ 0.51148504, -0.48513567],\n",
       "       [ 0.13303842, -0.138954  ],\n",
       "       [ 0.4591167 , -0.44120502],\n",
       "       [ 0.0871261 , -0.08732793],\n",
       "       [ 0.24394025, -0.2291471 ],\n",
       "       [ 0.6738007 , -0.631177  ],\n",
       "       [ 0.91707206, -0.8591704 ],\n",
       "       [-0.18579601,  0.17411399],\n",
       "       [ 0.45227867, -0.42930016],\n",
       "       [ 0.19918783, -0.1992268 ],\n",
       "       [-0.41141737,  0.3847223 ],\n",
       "       [ 0.77101743, -0.71299887],\n",
       "       [ 0.49678764, -0.4716914 ],\n",
       "       [ 0.6086605 , -0.5989874 ],\n",
       "       [ 0.7354508 , -0.6857837 ],\n",
       "       [ 0.08528285, -0.09517028],\n",
       "       [-0.08788244,  0.08300336],\n",
       "       [ 0.70655364, -0.67000324],\n",
       "       [ 0.24679329, -0.2368671 ],\n",
       "       [ 0.6976287 , -0.6582604 ],\n",
       "       [ 0.3337134 , -0.33648872],\n",
       "       [ 0.3454356 , -0.32658905],\n",
       "       [ 0.86161375, -0.79590577],\n",
       "       [ 0.23877126, -0.2317003 ],\n",
       "       [ 0.5456465 , -0.50814134],\n",
       "       [ 0.10760489, -0.09926186],\n",
       "       [ 0.5527006 , -0.5363477 ],\n",
       "       [ 0.74172443, -0.6681227 ],\n",
       "       [ 0.5765721 , -0.53766465],\n",
       "       [ 0.54882306, -0.5002431 ],\n",
       "       [ 0.26545832, -0.25082913],\n",
       "       [ 0.2756592 , -0.2651261 ],\n",
       "       [ 0.3347032 , -0.32318592],\n",
       "       [ 0.6544387 , -0.60446376],\n",
       "       [ 0.7233873 , -0.682157  ],\n",
       "       [ 0.7997853 , -0.73000973],\n",
       "       [ 0.05651512, -0.06815667],\n",
       "       [ 0.15874669, -0.17054334],\n",
       "       [ 0.73509103, -0.68427736],\n",
       "       [ 0.38499978, -0.36702883],\n",
       "       [ 0.70728296, -0.68274945],\n",
       "       [ 0.07308903, -0.08032428],\n",
       "       [ 0.7341265 , -0.69205475],\n",
       "       [ 0.28863913, -0.3032369 ],\n",
       "       [ 0.5219344 , -0.49204248],\n",
       "       [-0.58624107,  0.5377784 ],\n",
       "       [ 0.2571569 , -0.23640609],\n",
       "       [ 0.24519302, -0.25288582],\n",
       "       [ 0.6088392 , -0.5805792 ],\n",
       "       [ 0.06743921, -0.07310182],\n",
       "       [ 0.1664965 , -0.17047085],\n",
       "       [-0.1826036 ,  0.16494249],\n",
       "       [ 0.36343566, -0.34693095],\n",
       "       [ 0.49256653, -0.47663802],\n",
       "       [ 0.7751731 , -0.7216187 ],\n",
       "       [ 0.28222123, -0.26967892],\n",
       "       [ 0.7152584 , -0.656437  ],\n",
       "       [ 0.33647507, -0.3318811 ],\n",
       "       [ 0.4805565 , -0.4683076 ],\n",
       "       [ 0.62049925, -0.5919873 ],\n",
       "       [ 0.2691125 , -0.2513765 ],\n",
       "       [ 0.43336678, -0.42142004],\n",
       "       [ 0.05225081, -0.06391215],\n",
       "       [ 0.05746938, -0.06080011],\n",
       "       [ 0.19605117, -0.18608595],\n",
       "       [ 0.43354136, -0.40538943],\n",
       "       [ 0.3363059 , -0.32298237],\n",
       "       [ 0.10836627, -0.09434358],\n",
       "       [ 0.6970229 , -0.66457623],\n",
       "       [ 0.7545088 , -0.6925363 ],\n",
       "       [ 0.70300174, -0.6538431 ],\n",
       "       [ 0.21926226, -0.20990616],\n",
       "       [-0.58624107,  0.5377784 ],\n",
       "       [-0.13399129,  0.12170155],\n",
       "       [ 0.08331544, -0.07701422],\n",
       "       [ 0.9041103 , -0.8372471 ],\n",
       "       [ 0.11801729, -0.12008234],\n",
       "       [ 0.5456465 , -0.50814134],\n",
       "       [ 0.385912  , -0.36973885],\n",
       "       [ 0.59896326, -0.56680846],\n",
       "       [-0.41141737,  0.3847223 ],\n",
       "       [ 0.651033  , -0.61509037],\n",
       "       [ 0.16510502, -0.16694514],\n",
       "       [ 0.34093222, -0.33243734],\n",
       "       [ 0.36235395, -0.3551373 ],\n",
       "       [ 0.42011347, -0.41390574],\n",
       "       [ 0.11770924, -0.11486638],\n",
       "       [ 0.1480537 , -0.14746532],\n",
       "       [ 0.6439516 , -0.598185  ],\n",
       "       [ 0.69227046, -0.65748876],\n",
       "       [ 0.50252336, -0.49289906],\n",
       "       [ 0.3956038 , -0.3881057 ],\n",
       "       [-0.35447928,  0.3386011 ],\n",
       "       [ 0.60516316, -0.57677394],\n",
       "       [-0.2627163 ,  0.24143925],\n",
       "       [-0.7281529 ,  0.6823662 ],\n",
       "       [ 0.1480537 , -0.14746532],\n",
       "       [ 0.5912481 , -0.56118256],\n",
       "       [ 0.7303665 , -0.6920863 ],\n",
       "       [ 0.16774647, -0.15891291],\n",
       "       [ 0.56624275, -0.5286365 ],\n",
       "       [ 0.7048815 , -0.6727889 ],\n",
       "       [ 0.09400453, -0.09975398],\n",
       "       [ 0.05746915, -0.06079991],\n",
       "       [ 0.10192139, -0.09700786],\n",
       "       [ 0.05646238, -0.05695097],\n",
       "       [ 0.06966556, -0.07260004],\n",
       "       [ 0.32504776, -0.29844218],\n",
       "       [ 0.78612065, -0.7379946 ],\n",
       "       [ 0.63999873, -0.61684066],\n",
       "       [ 0.5768737 , -0.541742  ],\n",
       "       [ 0.62517196, -0.59546864],\n",
       "       [-0.04901075,  0.03416038],\n",
       "       [ 0.6126457 , -0.58854985],\n",
       "       [ 0.16541633, -0.1528789 ],\n",
       "       [ 0.45971832, -0.45196763],\n",
       "       [ 0.3572259 , -0.34089842],\n",
       "       [ 0.70949465, -0.6476852 ],\n",
       "       [-0.48524028,  0.47047544],\n",
       "       [ 0.7653792 , -0.72222847],\n",
       "       [ 0.6431423 , -0.6036794 ],\n",
       "       [ 0.09742463, -0.09571546],\n",
       "       [ 0.5635937 , -0.5386551 ],\n",
       "       [ 0.36392263, -0.33606252],\n",
       "       [ 0.30714512, -0.30280387],\n",
       "       [ 0.28222108, -0.2696788 ],\n",
       "       [ 0.5950317 , -0.5635218 ],\n",
       "       [ 0.74090856, -0.6913244 ],\n",
       "       [ 0.04495075, -0.06084999],\n",
       "       [ 0.37667394, -0.36278296],\n",
       "       [ 0.53065854, -0.48086333],\n",
       "       [ 0.08635604, -0.08488103],\n",
       "       [ 0.46948153, -0.43567425],\n",
       "       [ 0.73962075, -0.7005879 ],\n",
       "       [ 0.52019477, -0.47488782],\n",
       "       [ 0.11119943, -0.11105993],\n",
       "       [ 0.10518873, -0.10962661],\n",
       "       [ 0.73036647, -0.69208616],\n",
       "       [ 0.5807571 , -0.5408868 ],\n",
       "       [ 0.6947715 , -0.6728478 ],\n",
       "       [ 0.15897436, -0.16571826],\n",
       "       [-0.10768379,  0.10326467],\n",
       "       [ 0.39083055, -0.36377844],\n",
       "       [-0.01937663,  0.00837075],\n",
       "       [ 0.1605585 , -0.13226706],\n",
       "       [ 0.41880727, -0.39788723],\n",
       "       [ 0.7584403 , -0.69026697],\n",
       "       [ 0.04388979, -0.0380532 ],\n",
       "       [ 0.26076993, -0.2505219 ],\n",
       "       [-0.2831933 ,  0.2693135 ],\n",
       "       [ 0.39582467, -0.3831553 ],\n",
       "       [ 0.26715243, -0.26293123],\n",
       "       [-0.01989091,  0.01070116],\n",
       "       [ 0.8256083 , -0.78152514],\n",
       "       [ 0.59896326, -0.56680846],\n",
       "       [ 0.51199   , -0.4781105 ],\n",
       "       [ 0.69565755, -0.64627665],\n",
       "       [ 0.90813345, -0.85576683],\n",
       "       [ 0.90620124, -0.8466441 ],\n",
       "       [ 0.1424983 , -0.14338553],\n",
       "       [ 0.2887628 , -0.2790646 ],\n",
       "       [ 0.72417974, -0.6561818 ],\n",
       "       [ 0.6630301 , -0.63529766],\n",
       "       [ 0.38070515, -0.37495345],\n",
       "       [ 0.8547234 , -0.7822657 ],\n",
       "       [ 0.7150741 , -0.6777232 ],\n",
       "       [ 0.6130235 , -0.60192066],\n",
       "       [ 0.46333367, -0.43035892],\n",
       "       [-0.5936916 ,  0.5737917 ],\n",
       "       [-0.27226582,  0.24562162],\n",
       "       [-0.5614451 ,  0.5240521 ],\n",
       "       [ 0.1664965 , -0.17047085],\n",
       "       [-0.68373924,  0.66324884],\n",
       "       [ 0.60516316, -0.57677394],\n",
       "       [-0.02911652,  0.02737202],\n",
       "       [ 0.5832461 , -0.55191636],\n",
       "       [ 0.77101743, -0.71299887],\n",
       "       [ 0.6382738 , -0.58300614],\n",
       "       [ 0.49708077, -0.4730151 ],\n",
       "       [ 0.38070518, -0.37495348],\n",
       "       [ 0.5753406 , -0.5471094 ],\n",
       "       [-0.5666329 ,  0.5297992 ],\n",
       "       [ 0.3639225 , -0.33606237],\n",
       "       [ 0.38736713, -0.36592966],\n",
       "       [ 0.2428355 , -0.24046995],\n",
       "       [ 0.90883446, -0.8435053 ],\n",
       "       [ 0.00603376, -0.03132779],\n",
       "       [ 0.5753406 , -0.5471094 ],\n",
       "       [ 0.28303552, -0.267028  ],\n",
       "       [ 0.5661574 , -0.5217455 ],\n",
       "       [ 0.56624275, -0.5286365 ],\n",
       "       [ 0.2163088 , -0.21103759],\n",
       "       [ 0.54604495, -0.52685446],\n",
       "       [ 0.5602188 , -0.5340413 ],\n",
       "       [ 0.19110827, -0.17587797],\n",
       "       [ 0.69227034, -0.65748864],\n",
       "       [ 0.5505421 , -0.51951617],\n",
       "       [ 0.6086171 , -0.56624204],\n",
       "       [ 0.15724327, -0.16727813],\n",
       "       [ 0.6533617 , -0.60816693],\n",
       "       [ 0.4969737 , -0.46634272],\n",
       "       [ 0.05780138, -0.04766334],\n",
       "       [ 0.03643588, -0.04122982],\n",
       "       [ 0.91707206, -0.8591704 ],\n",
       "       [ 0.5765721 , -0.53766465],\n",
       "       [ 0.74172443, -0.6681227 ],\n",
       "       [ 0.70491064, -0.68747526],\n",
       "       [ 0.06961389, -0.07390036],\n",
       "       [ 0.49708086, -0.47301516],\n",
       "       [ 0.62926525, -0.6007282 ],\n",
       "       [ 0.2236195 , -0.23088731],\n",
       "       [ 0.45911676, -0.44120508],\n",
       "       [ 0.15085159, -0.13727929],\n",
       "       [-0.01528387,  0.01070029],\n",
       "       [ 0.72294   , -0.6852019 ],\n",
       "       [ 0.4024793 , -0.4016654 ],\n",
       "       [ 0.0928823 , -0.10507053],\n",
       "       [ 0.6476589 , -0.63923615],\n",
       "       [ 0.7949415 , -0.7238074 ],\n",
       "       [ 0.6185706 , -0.5665701 ],\n",
       "       [ 0.7001523 , -0.6371172 ],\n",
       "       [ 0.23587209, -0.21989197],\n",
       "       [ 0.3623651 , -0.35237694],\n",
       "       [-0.2532669 ,  0.21893202],\n",
       "       [ 0.45371452, -0.43041325],\n",
       "       [ 0.07428794, -0.07265517],\n",
       "       [ 0.01230413, -0.02348869],\n",
       "       [ 0.39363062, -0.36452854],\n",
       "       [ 0.43074554, -0.42079443],\n",
       "       [-0.5899834 ,  0.5593144 ],\n",
       "       [ 0.706507  , -0.6625816 ],\n",
       "       [ 0.6151247 , -0.5706177 ],\n",
       "       [-0.09504436,  0.08121914],\n",
       "       [ 0.66333294, -0.6178632 ]], dtype=float32)), label_ids=None, metrics={'test_runtime': 24.3748, 'test_samples_per_second': 16.123, 'test_steps_per_second': 2.051})"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 0 0 1 0 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 1 0 1 0 0 1 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 1 0 1 0\n",
      " 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 1 0 0 1 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 0 0 0 0 0 1 0 1 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 1 1 1 1 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 1 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 1 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 1 0\n",
      " 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 1 0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5725190839694656"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.special import softmax\n",
    "\n",
    "# converting logits into predicted labels\n",
    "logits = np.array(predictions[0][-1])\n",
    "probabilities = softmax(logits, axis=1)\n",
    "predicted_classes = np.argmax(probabilities, axis = 1)\n",
    "print(predicted_classes)\n",
    "test_dataset[\"label\"]\n",
    "\n",
    "compute_metrics(predicted_classes, test_dataset[\"label\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make predictions for X notes data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare classifier predictions to human predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# my idea for how to evaluate:\n",
    "# 1) we set some guidelines for how we will evaluate notes \n",
    "# 2) we individually make labels for one days worth of notes (that's about 200 notes; this would be the train set)\n",
    "# 3) we calculate out interrater agreement (if it's very bad, we revise our guidelines and re-label)\n",
    "# 4) we average our labels and use that to further fine-tune the classifier\n",
    "# 5) we repeat step 2 on a new set of notes (this would be the test set)\n",
    "# 6) we make predictions using the classifier obtained from step 4\n",
    "# 7) either we calculate the MSE using our labels as ground truth, or we calculate three interrater agreements (chico-andrew, chico-classifier, andrew-classifier)\n",
    "# and see if the human-human agreement is better than the human-classifier agreement.\n",
    "..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
